## Monday {{date}}

- [x] [Update Telework](https://docs.google.com/spreadsheets/d/16AZZBiKL1s6eGgH2KFiJPnD8-TjRsC0HYy4Qdmbr358/edit#gid=0) ✅ 2022-04-18
- [ ] 0830AM [NPPS Coffee](https://bnl.zoomgov.com/j/16157150845?pwd=NXNqTi9ZWEFBKzYwRXQ5U3NXU1dBZz09)

- Note-taking... added code to the cronjobs to automatically create the folder for the week's notes... next week will setup to automatically create the day's template.
- [x] Time to add task tracking to this as well... ✅ 2022-04-18

SHREK
---
Brain is not sufficiently caffeinated this morning.  But.  Recalling where I left off last week, ... ready to start implementing the tools to create the submission package.

Central to this is the 'YamlHandler'... which will take the dictionary read in from the yaml input file, and create the submission scripts, workflows, etc...

....

As I am going through this, I am starting to realize that I should create a set of classes to read the data into.   Then individual tools to create the required documents from those classes... (... )

...

NOTE:  Schema does not currently *require* that important fields (such as name) are present in input data sets... and other structures.  If careless, can result in more (and bad) entries in input lists that we want.  

With latest commit...
https://github.com/klendathu2k/shrek/commit/4e1becb7ac0864768805abb71f8713b4c2343e92?diff=split

All of the job parameters, commands, etc... are parsed into their own data classes.

Based on these classes we can build an independent workflow and submit it to PanDA.

To make this fully functional:

- [ ] Add JobDefinition class
	- Represents single YAML file defined by the user to define one job
- [ ] Add Workflow Class (multiple JobDefinitions)
	- Represents a workflow to be submitted to PanDA
	- Built up from a list of job definition files provided by the user
	- Constructs a DAG from the job definitions, with the inputs / outputs forming the edges.
