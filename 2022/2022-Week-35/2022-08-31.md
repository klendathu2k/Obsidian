## Wednesday {{date}}

- [ ] 0830AM [NPPS Coffee](https://bnl.zoomgov.com/j/16157150845?pwd=NXNqTi9ZWEFBKzYwRXQ5U3NXU1dBZz09)
- [ ] 1000AM [sPHENIX Distributed Computing](https://bnl.zoomgov.com/j/16157150845?pwd=NXNqTi9ZWEFBKzYwRXQ5U3NXU1dBZz09)
- [ ] 1200PM [STAR S&C Meeting](https://lbnl.zoom.us/j/97026562983?pwd=VGVXbzhYUUhheEJ2cFMyVVdVRXowZz09)

More on the dynamic polymorphic ordered memory concept...

```
#include <variant>
#include <string>
#include <vector>
#include <iostream>
#include <typeinfo>

template<typename... Ts>
class Qstore : public std::vector<std::variant<Ts...>>
{

  int id;
  std::string name;

public:
  template<typename T>
  T* At( const int index ){ return std::get_if<T>( &(*this)[index] ); }
  
};


struct A {
  int a = 1;
};

struct B {
  float b = 2.0f;
};

struct C {
  double c = 3.0;
};

struct D {
  std::string d = "four";
};

Qstore< A, B, C, D > Q;

int main() {

  int j=0;
  for ( int i=0; i<100; i++ ) { 
    Q.resize(4*(i+1));
    Q[j++].emplace<A>( A{1} );
    Q[j++].emplace<B>( B{2.0f} );
    Q[j++].emplace<C>( C{3.0} );
    Q[j++].emplace<D>( D{"four"} );

  }
    
  std::cout << " ... " << std::endl;
  std::cout << "Q.size() = " << Q.size() << std::endl;
  for (auto& q: Q){
    std::visit([](auto arg){std::cout << &arg << " " << typeid(arg).name() << std::endl;}, q);
  }

  std::cout << " ... " << std::endl;
  j=0;
  for ( int i=0;i<100;i++ ) {
    A* a = Q.At<A>(j++);
    B* b = Q.At<B>(j++);
    C* c = Q.At<C>(j++);
    D* d = Q.At<D>(j++);
    std::cout << a << " " << a->a << std::endl;
    std::cout << b << " " << b->b << std::endl;
    std::cout << c << " " << c->c << std::endl;
    std::cout << d << " " << d->d << std::endl;    
  };

  return 1;

};
```

Running the above code... seeing the expected behavior.  The constructed objects are contiguous in memory.


-----------------------

[1k event jobs do not pass time constraints](https://panda-doma.cern.ch/jobs/?jeditaskid=133492&mode=nodrop&display_limit=100)

Need to figure out why...

-----------------------

Thinking through the sPHENIX production system.... So...

Data will be accumulated at the experiment, and pushed out to storage somewhere... probably represented as a dataset in rucio.  So...

If each dataset follows a naming convention which encodes the date and time...  something like

yyyy-mm-dd-blah-filesequence.daq

We can run a process which periodically queries rucio.  It should build a list of daq files which are newly found, and prepare to submit them as inputs to a workflow.  And then submit them.

1) Process would need to have persistency... it should record in a DB (or somewhere eg github) the previously processed daq files.
2) Should look at the PanDA queue and ensure that unprocessed jobs are not piling up.
3) Should have a prescale factor for processing runs... (e.g. 3=take every third run)... so that we don't pileup too many unprocessed runs.

We will need to look to make sure that the dataset is closed (metadata flag is set)

How to query dataset metadata?

----------------

Material plot code...

Was a generalization of
https://root.cern/doc/master/TGeoChecker_8cxx_source.html#l02040

But ... does not step into some of the intermediate (air) volumes?  Por que?  And does it matter?  The issue with the 





