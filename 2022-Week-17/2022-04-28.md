## Thursday {{date}}

SHREK
---

As of yesterday, the simple workflow example validates through panda.  More complicated chain requires a minor reshape of how input data sets are handled.

...

Okay.  There's a design choice to be made here.  It is somewhat minor, but should be done right.  It has to do with how the inputs are specified.  Thus far, the job description files define an InputDataSet, which takes a name.  But that name is a "variable name".  A placeholder to represent one (or more) input data sets.  That name is used to connect up with the output data sets when building the workflow graph.  (This mirrors precisely the PanDA pchain / cwl syntax).  PanDA/CWL then specifies the actual datasets in an input file, mapping those data sets onto the variable names declared in the CWL.

My original plan was to attach the datasets to the InputDataSet in the job definition files.  This would keep the full definiton in the JDFs.  What I overlooked is that multiple jobs can share the same input.  The consequence here is that the InputDataSet object can be defined in multiple places throughout the submission codes.   This is  error prone.  A user may define a "background" InputDS in make_background_1.yaml, and attach it to three different datasets.  Using "background" InputDS in make_background_2.yaml...  if a user defines a different list of data sets... what should be done here?  (a) merge the sets?  (b) drop the second definition?  (c) issue an error?

Each of these are problematic.  (a) merging could result in unexpected results when codes are retooled for a new production pass.  (b) dropping the second definition... depends on order in which the yaml files are processed... (c) issueing an error... user has to find where to adjust the DS definiton...  // option c appears the least problematic... inconvience versus error prone...  there should be a single definiton for this information...

Better option woudl be to define one more job definition file... an inputs/outputs file.  With no JobCommands block... which removes it from the CWL file.

Actually... outputs can / should be discovered from the structure of the document.

Added rule:  any job definition with purely inputs will be parsed seperately to create the inputs.yaml file used during pchain submission.

TODO: Need to expose the created yaml file to the testing framework

