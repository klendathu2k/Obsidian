## Thursday {{date}}

Okay.  Setup a test using the simple 2:1 test workflow.

top1 has 3 jobs, with wildcard used to specify the output file
top2 has 3 jobs, with wildcard used to specify the output file

bottom brings in data sets... using wildcards.

Without the wildcards, I know how this is supposed to behave.  There will be three jobs in the bottom part of the workflow.

Wait a tick... no, I don't *know* that.  I *assume* that.  Looking at the result file from the previous tests... bottom may be recieving all of the inputs in a single "dataset..."

Okay.  Once again my assumptions about how things *should* work (based on SUMS) run up against how they actually work under panda.  Looks like I need to do a [scatter](https://panda-wms.readthedocs.io/en/latest/client/pchain.html#sub-workflow-and-parallel-execution-with-scatter) operation.  

And then... 

Documentation by example (pchain) is not sufficient

e.g. [simple chain](https://panda-wms.readthedocs.io/en/latest/client/pchain.html#simple-task-chain)

Does not specify the number of output files which is expected from the bottom part of the chain.

This linear workflow does not behave as I expect... however... I am missing one flag... --forceStaged:

```
  --forceStaged         Force files from primary DS to be staged to 
                        local disk, even if direct-access is possible
  --forceStagedSecondary
                        Force files from secondary DSs to be staged to 
						local disk, even if direct-access is possible

```

Okay... suspect that I cannot just do a scatter over a prun... but rather scatter *must* involve a sub workflow...  There is a word that comes to mind here.  Rhymes with duck.  There was a design decision that was made a while ago that assumed 



