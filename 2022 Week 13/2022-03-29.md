sPHENIX Production System...
- Issue yesterday was that I was specifying an incorrect prodSourceLabel... "test" is allowed.  "test_jcw"... not so much.  This is more than just a "label", as it impacts which work ques jobs are assigned to...
- Can the --nJobs be parameterized?  It is set as an opt_ arguement in the workflow examples, but the CWL language suggests that is just somewhat arbitrary...
	- Unclear...  It doesn't look like I can add a parameter
- Think I realize that there are two ways to run multiple jobs.  One of which is to scatter across an input dataset.  The other is to specify nJobs.
- ... so ...  bleh.  Too many ways to do things...  design space is wide open still.


- Back to working on the envirnonment for the jobs, plus staging the macros...
	- CWL documentation / examples are basically useless for copying the contents of an existing directory into the running area... so,...
	- panda pchain will already stage the entire directory tree from under where I am running
	- init-env script can then execute an arbitrary copy command, provided by the user in the yaml file...
	- Have this setup... ran pchain --check ... and it checked out.  So go ahead and submit... code is "running" forever.  All this is is "hello world", why is it taking so damn long?  Why???
		- Job failed and did not cat output to local text file... por que no?
		- 


- Following the pass1 generation (with pass1 signals in hand...) the pass2 workflow will be a scatter operation over signal events and background events, [similar to this workflow](https://panda-wms.readthedocs.io/en/latest/client/pchain.html#sub-workflow-and-parallel-execution-with-scatter)
	- The inputs would need to be file lists... single file per signal signal, multiple files per background list