## Highlights Week 13

Implemented the following prototype using plain vanilla `cwl-runner`... no pchain submission:

Have the following proof-of-concept:
```
$ cwl-runner shrek.cwl run_hfcharm_pass1.yaml
```

The `shrek.cwl` file takes as input a user-specied job configuration file (`.yaml` file) which specifies all of the job's properties...

``` 
$ cat run_hfcharm_pass1.yaml

# Specifies a unique name for the job                                  
jobname: g4charm                                                                                                     
# Extra panda flags (such as number of jobs to run)              
extra_panda_args: --nJobs 5                        

# sPHENIX software build level                                         build: mdc2.7                                                           

# Job parameters
nevents: 100    # to generate                                            type: Charm     # type of job                                            outfile: TestSubmission                                                 outdir: /sphenix/user/sphnxpro/shrek/pass1/out                         logdir: /sphenix/user/sphnxpro/shrek/pass1/log                         jobdir: /sphenix/u/jwebb2/work/2022/SHREK/MDC2                                       
runnumber: 1234567890                                                   

# Commands to stage files required to run the code 
stagecmd: |-                                                          
  ln -s /sphenix/u/jwebb2/work/2022/SHREK/MDC2/submit/HF_pp200_signal/pass1/rundir/* .                                                   
                                        
# Command block                                                        
commands: |-                                                           
  echo execute a predefined script                                     
  run_hfprod_pass1.sh                                                  
  echo or any arbitrary set of unix commands...                        
  # e.g. root.exe -q -b Fun4All.C                                 
  
# Copy back block                                                       
copyback: |-                                                                                                                             
  ls > ${g4charm_RUNNUM}_${g4charm_SEQNUM}.manifest     

```

The `stagecmd`, `commands` and `copyback` blocks are merged into shell script, which is generated by the cwl runner.  That shell script (per CWL specification) will be created as part of the inital working directory.  The `shrek.cwl` workflow is responsible for exposing the parameters specified in the yaml file as environment variables, and copying the user's command blocks into the script at appropriate points.  

`shrek.cwl` (in the standalone test-rig above) implements a command line tool wrapper around the *generated* script.

For the production system, `shrek.cwl` is a workflow that `submits the generated script` via prun.

(This is essenially the way that SUMS works... and it provides a very natural environment for users to run their code...)

![[Pasted image 20220401161923.png|400]]
*when all you have is a hammer...*

Herein lies the problem.  Which pchain is invoked, it starts by building a tarball of the current working directory tree (minus files over a large size limit).  That tarball is sent to the PanDA server, where the workflow is executed.  Based on some tests I am fairly confident that the tarball is not unpacked / repacked on the PanDA server.  So the files which are generated by CWL (that I need) are not sent to the worker node for processing.  

Emailing Tadashi to confirm, and ask if this is a feature that would be reasonable to add.  (By this... I mead adding any files that CWL creates to the tarball)

There are other possible workarounds...
- CWL has some degree of introspection.  I believe that *its* runtime location is available as an $(input.variable). I may be able to add those files to the tarball myself...
- I wonder if there is a real advantage to running the workflow on the PanDA server, versus running it on a local system.  I suppose monitoring is the big thing... but each of the prun tasks would be monitored, and the overall workflow progress could be tracked by watching output and log directories...
- Might be able to reshape... 
	- Instead of prun submitting the script generated by the CWL... it runs the CWL on the remote node.  (This looks like a cleaner solution to me at the moment...)


[[SHREK]]