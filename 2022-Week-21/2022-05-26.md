## Thursday {{date}}

On Tuesday, Kolja was looking for a "hello world" example for PanDa... b/c he was having some troubles.   SHREK  did not work for him out of the box b/c there are alot of unresoved dependencies...  so googled for a new trick:

[How to list project dependencies in python](https://stackoverflow.com/questions/42237072/list-dependencies-in-python)

After yesterday's meeting, and given lack of email today... looks like it may be a while before PanDA actually works at BNL.  Beyond being able to run single stage (in --> job --> out) type jobs.  But need to make progress on setting up the sPHENIX workflow...

So...

Setup jobs and copy back results, then run the pileup by hand.  Setup downstream workflow using a direct link to the inputs.  

Let's make this a reasonable simulation... so need some info...
https://arxiv.org/pdf/2110.02082.pdf

Okay... order of magnitude w/ repect ot STAR... so assume ~40 bxings... This is pp (assume pp500) so ~1 interaction / bxing...  Running 50 minb events / charm event seems to be about right.  But scale x2... so 100 minb per charm.

Alrighty... [setup and](https://panda-doma.cern.ch/tasks/?jeditaskid=67170|67171) [waiting...](https://www.youtube.com/watch?v=uMyCa35_mOg)

Files will be copied direct to /sphenix/u/sphnxpro/shrek/

Okay... been waiting half an hour for the job to start running... (And there are other peoples jobs in the monitor which are also waiting.)  This is ridiculous. It is *painful* to setup any workflow in PanDA.  Yarg!

Three hours now...  YARGH!

Create two new yaml files... one to run pileup on files copied direct

---

More debate on StEvent... Akio really wants to add an extra int (primary track parent id) which will have zero additional physics content.   My innate obstinance may be an asset here.

---

Have a review (finally) on [PR #308](https://github.com/star-bnl/star-sw/pull/308/checks)
- 


